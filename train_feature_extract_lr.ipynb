{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298 total samples.\n"
     ]
    }
   ],
   "source": [
    "# csv containing filename, subject_id_and_knee, is_right, TKR, visit, and all extracted features. Generated by create_feature_extractions script.\n",
    "\n",
    "path = \"feature_extract.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "subject_id_and_knee = lambda row: str(row[\"ID\"]) + (\"-R\" if row[\"is_right\"] else \"-L\")\n",
    "df[\"subject_id_and_knee\"] = df.apply(subject_id_and_knee, axis=1)\n",
    "\n",
    "print(f\"{df.shape[0]} total samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying patients with at least n visits\n",
    "n_visits = 1\n",
    "visits = df[\"subject_id_and_knee\"].value_counts()\n",
    "visits_df = df[df[\"subject_id_and_knee\"].isin(visits.index[visits.gt(n_visits - 1)])]\n",
    "indices = list(list(zip(*visits_df.groupby(\"subject_id_and_knee\")['visit'].nlargest(n_visits).index.values))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232 samples with at least 1 visits.\n"
     ]
    }
   ],
   "source": [
    "# Rows for patients with at least n visits\n",
    "subjects_df = df.iloc[indices].fillna(0.)\n",
    "\n",
    "n_uniq = subjects_df[\"subject_id_and_knee\"].unique().shape[0] \n",
    "print(f\"{n_uniq} samples with at least {n_visits} visits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 38)\n"
     ]
    }
   ],
   "source": [
    "# Creating dataset\n",
    "exclude_columns = {\"ID\", \"is_right\", \"visit\", \"filename\", \"subject_id_and_knee\", \"TKR\"}\n",
    "include_columns = list(set(df.columns.values) - exclude_columns)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for subject_id in subjects_df[\"subject_id_and_knee\"].unique():\n",
    "    subject_rows = subjects_df[subjects_df[\"subject_id_and_knee\"] == subject_id][include_columns]\n",
    "    features = np.array([row.values for _, row in subject_rows.iterrows()]).reshape(-1)\n",
    "    X.append(features)\n",
    "    \n",
    "    tkr = subjects_df[subjects_df[\"subject_id_and_knee\"] == subject_id][\"TKR\"].values[0]\n",
    "    y.append(int(tkr))\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 training samples and 58 test samples.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "print(f\"{y_train.shape[0]} training samples and {y_test.shape[0]} test samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To normalize or not?\n",
    "normalizer = Normalizer().fit(X_train)\n",
    "X_train_normalized = normalizer.transform(X_train)\n",
    "X_test_normalized = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train_normalized, y_train)\n",
    "y_pred = reg.predict(X_test_normalized)\n",
    "y_pred = (y_pred >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics for linear regression classifier (58 test samples):\n",
      "Accuracy:    0.7414\n",
      "Precision:   0.5455\n",
      "Recall:      0.3750\n",
      "Specificity: 0.8810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "eps = 1e-6\n",
    "accuracy = (tp + tn) / (tn + fp + fn + tp + eps)\n",
    "precision = tp / (tp + fp + eps)\n",
    "recall = tp / (tp + fn + eps)\n",
    "specificity = tn / (tn + fp + eps)\n",
    "\n",
    "print(f\"\"\"\n",
    "Test metrics for linear regression classifier ({y_test.shape[0]} test samples):\n",
    "Accuracy:    {accuracy:.4f}\n",
    "Precision:   {precision:.4f}\n",
    "Recall:      {recall:.4f}\n",
    "Specificity: {specificity:.4f}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:15:33) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "50c72791533b2e456d410907430853874ee556395215cfd7c62eb72d563d8e2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
