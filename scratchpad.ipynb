{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import pad\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from skimage.io import imread, imsave\n",
    "from tqdm import tqdm\n",
    "\n",
    "from thesisproject.data import ImageData, SliceLoader\n",
    "from thesisproject.models import UNet, LitUNet\n",
    "from thesisproject.utils import get_metrics, mask_to_rgb, segmentation_to_rgb\n",
    "from thesisproject.train import training_loop, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a592e4-b905-4a70-9673-522f8e998d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Square_pad:\n",
    "    def __init__(self, fill=0):\n",
    "        self.fill=fill\n",
    "\n",
    "    def __call__(self, image: Tensor):\n",
    "        imsize = image.shape\n",
    "        max_edge = np.argmax(imsize)\n",
    "        pad_amounts = [imsize[max_edge] - imsize[0], imsize[max_edge] - imsize[1], imsize[max_edge] - imsize[2]]\n",
    "\n",
    "        padding = [pad_amounts[0], 0, pad_amounts[1], 0, pad_amounts[2], 0] #left, right, top, bottom, front, back\n",
    "        padding = tuple(padding[::-1])\n",
    "\n",
    "        padded_im = F.pad(image, padding, \"constant\", self.fill)\n",
    "        return padded_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea3ee05-4b97-418e-a4a5-271dc1d74086",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"../ScanManTrain61_knee_data/\"\n",
    "\n",
    "transform = Square_pad()\n",
    "\n",
    "train_data = ImageData(path + \"train\", transform=transform, target_transform=transform, num_access=5)\n",
    "val_data = ImageData(path + \"val\", transform=transform, target_transform=transform, num_access=5)\n",
    "\n",
    "train_loader = SliceLoader(train_data, slices_per_batch=8, volumes_per_batch=4, shuffle=True, num_workers=4, pin_memory=False)\n",
    "val_loader = SliceLoader(train_data, slices_per_batch=8, volumes_per_batch=4, shuffle=False, num_workers=4, pin_memory=False)\n",
    "\n",
    "## Train\n",
    "net = LitUNet(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b139eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
